{
 "cells": [
  {
   "cell_type": "code",
   "id": "4c06e221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:16:34.233924Z",
     "start_time": "2025-11-22T14:16:32.990051Z"
    }
   },
   "source": [
    "#load the packages\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "from torch.utils.data import Dataset, DataLoader"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "e5ff5d5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-22T14:17:51.150918Z",
     "start_time": "2025-11-22T14:17:49.212085Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================\n",
    "#                 CONFIGURATION a CHANGE\n",
    "# ============================================================\n",
    "CSV_PATH = r\"C:\\Users\\giuli\\PycharmProjects\\DeepL_project_test\\data\\filtered_games.csv\"  # Your dataset\n",
    "\n",
    "LIST_OF_PLAYERS = [\n",
    "    \"Carlsen, Magnus\",\n",
    "    \"Firouzja, Alireza\",\n",
    "    \"Caruana, Fabiano\",\n",
    "    \"Nepomniachtchi, Ian\",\n",
    "    \"Cramling Bellon, Anna\",\n",
    "    \"Giri, Anish\",\n",
    "    \"Niemann, Hans Moke\",\n",
    "    \"Cramling, Pia\",\n",
    "    \"Nakamura, Hikaru\",\n",
    "    \"Botez, Alexandra\",\n",
    "    \"Botez, Andrea\",\n",
    "    \"Belenkaya, Dina\",\n",
    "    \"So, Wesley\",\n",
    "]\n",
    "\n",
    "# ---- Only use FIRST 4 players ----\n",
    "PLAYERS = LIST_OF_PLAYERS[:4]\n",
    "\n",
    "MAX_LEN = 60\n",
    "BATCH_SIZE = 256\n",
    "EMB_DIM = 128\n",
    "HIDDEN_DIM = 128\n",
    "EPOCHS = 30\n",
    "LR = 2e-3\n",
    "\n",
    "# ============================================================\n",
    "#                 LOAD CSV\n",
    "# ============================================================\n",
    "print(\"Loading CSV...\")\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "df[\"white_name\"] = df[\"white_name\"].astype(str)\n",
    "df[\"black_name\"] = df[\"black_name\"].astype(str)\n",
    "\n",
    "# ============================================================\n",
    "#                 LABEL CONSTRUCTION (5 players only)\n",
    "# ============================================================\n",
    "def extract_player(name):\n",
    "    for p in PLAYERS:\n",
    "        if p.lower() in name.lower():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "df[\"label\"] = df.apply(\n",
    "    lambda row: extract_player(row[\"white_name\"]) or extract_player(row[\"black_name\"]),\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Keep ONLY games involving the first 5 players\n",
    "df = df[df[\"label\"].notna()].reset_index(drop=True)\n",
    "\n",
    "print(\"Games left after filtering:\", len(df))\n",
    "print(df[\"label\"].value_counts())\n",
    "\n",
    "# ============================================================\n",
    "#                 MOVE TOKENIZATION\n",
    "# ============================================================\n",
    "print(\"Building vocabulary...\")\n",
    "\n",
    "all_moves = []\n",
    "for moves in df[\"list_of_moves\"]:\n",
    "    moves = moves.strip(\"[]\").replace(\"'\", \"\").replace(\",\", \"\")\n",
    "    tokens = moves.split()\n",
    "    all_moves.extend(tokens)\n",
    "\n",
    "move_counts = Counter(all_moves)\n",
    "\n",
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for move in move_counts:\n",
    "    vocab[move] = len(vocab)\n",
    "\n",
    "with open(\"vocab.json\", \"w\") as f:\n",
    "    json.dump(vocab, f)\n",
    "\n",
    "# ============================================================\n",
    "#                 DATASET CLASS\n",
    "# ============================================================\n",
    "label2id = {name: i for i, name in enumerate(PLAYERS)}\n",
    "id2label = {i: name for name, i in label2id.items()}\n",
    "\n",
    "def encode_moves(moves):\n",
    "    tokens = moves.strip(\"[]\").replace(\"'\", \"\").replace(\",\", \"\").split()\n",
    "    idxs = [vocab.get(t, 1) for t in tokens][:MAX_LEN]\n",
    "    while len(idxs) < MAX_LEN:\n",
    "        idxs.append(0)\n",
    "    return idxs\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        moves = encode_moves(row[\"list_of_moves\"])\n",
    "        label = label2id[row[\"label\"]]\n",
    "        return torch.tensor(moves, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "# ============================================================\n",
    "#                 TRAIN/VAL/TEST SPLIT\n",
    "# ============================================================\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=42, shuffle=True)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=42, shuffle=True)\n",
    "\n",
    "train_loader = DataLoader(ChessDataset(train_df), batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(ChessDataset(val_df),   batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader  = DataLoader(ChessDataset(test_df),  batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# ============================================================\n",
    "#                 MODEL\n",
    "# ============================================================\n",
    "class ChessRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.rnn = nn.GRU(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, h = self.rnn(x)\n",
    "        h = self.dropout(h.squeeze(0))\n",
    "        return self.fc(h)\n",
    "\n",
    "model = ChessRNN(len(vocab), EMB_DIM, HIDDEN_DIM, len(label2id))\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "# ============================================================\n",
    "#                 TRAINING LOOP\n",
    "# ============================================================\n",
    "print(\"Training model...\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for X, y in tqdm(train_loader, colour='green'):\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(X)\n",
    "        loss = criterion(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = logits.argmax(dim=1)\n",
    "        correct += (preds == y).sum().item()\n",
    "        total += len(y)\n",
    "\n",
    "    train_acc = correct / total\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for Xv, yv in val_loader:\n",
    "            preds = model(Xv).argmax(dim=1)\n",
    "            val_correct += (preds == yv).sum().item()\n",
    "            val_total += len(yv)\n",
    "\n",
    "    val_acc = val_correct / val_total\n",
    "\n",
    "    print(\n",
    "        f\"Epoch {epoch+1}/{EPOCHS} \"\n",
    "        f\"Loss = {total_loss:.3f}  \"\n",
    "        f\"Train Acc = {train_acc:.3f}  \"\n",
    "        f\"Val Acc = {val_acc:.3f}\"\n",
    "    )\n",
    "\n",
    "# ============================================================\n",
    "#                 FINAL TEST ACCURACY\n",
    "# ============================================================\n",
    "print(\"Evaluating test accuracy...\")\n",
    "\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for Xt, yt in test_loader:\n",
    "        preds = model(Xt).argmax(dim=1)\n",
    "        test_correct += (preds == yt).sum().item()\n",
    "        test_total += len(yt)\n",
    "\n",
    "print(f\"FINAL TEST ACCURACY = {test_correct / test_total:.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "#                 SAVE MODEL\n",
    "# ============================================================\n",
    "torch.save(model.state_dict(), \"rnn_player_classifier.pt\")\n",
    "print(\"Model saved as rnn_player_classifier.pt\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading CSV...\n",
      "Games left after filtering: 24348\n",
      "label\n",
      "Carlsen, Magnus        7726\n",
      "Caruana, Fabiano       6418\n",
      "Nepomniachtchi, Ian    5157\n",
      "Firouzja, Alireza      5047\n",
      "Name: count, dtype: int64\n",
      "Building vocabulary...\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'vocab.json'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mPermissionError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 87\u001B[39m\n\u001B[32m     84\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m move \u001B[38;5;129;01min\u001B[39;00m move_counts:\n\u001B[32m     85\u001B[39m     vocab[move] = \u001B[38;5;28mlen\u001B[39m(vocab)\n\u001B[32m---> \u001B[39m\u001B[32m87\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mvocab.json\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mw\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[32m     88\u001B[39m     json.dump(vocab, f)\n\u001B[32m     90\u001B[39m \u001B[38;5;66;03m# ============================================================\u001B[39;00m\n\u001B[32m     91\u001B[39m \u001B[38;5;66;03m#                 DATASET CLASS\u001B[39;00m\n\u001B[32m     92\u001B[39m \u001B[38;5;66;03m# ============================================================\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001B[39m, in \u001B[36m_modified_open\u001B[39m\u001B[34m(file, *args, **kwargs)\u001B[39m\n\u001B[32m    336\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m}:\n\u001B[32m    337\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    338\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mIPython won\u001B[39m\u001B[33m'\u001B[39m\u001B[33mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m by default \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    339\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    340\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33myou can use builtins\u001B[39m\u001B[33m'\u001B[39m\u001B[33m open.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    341\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m343\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mPermissionError\u001B[39m: [Errno 13] Permission denied: 'vocab.json'"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
