{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c06e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ff5d5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 39/39 [00:35<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration nr 1 out of 30  running loss =  52.4106   training accuracy =  0.3338   validation accuracy =  0.3648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 39/39 [00:36<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration nr 2 out of 30  running loss =  50.3488   training accuracy =  0.3950   validation accuracy =  0.3817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 39/39 [00:44<00:00,  1.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration nr 3 out of 30  running loss =  48.0946   training accuracy =  0.4403   validation accuracy =  0.4018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 39/39 [00:54<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration nr 4 out of 30  running loss =  45.6571   training accuracy =  0.4880   validation accuracy =  0.3965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 39/39 [00:48<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration nr 5 out of 30  running loss =  41.7157   training accuracy =  0.5516   validation accuracy =  0.4088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[32m██████████\u001b[0m| 39/39 [00:45<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration nr 6 out of 30  running loss =  36.1503   training accuracy =  0.6257   validation accuracy =  0.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|\u001b[32m█▎        \u001b[0m| 5/39 [00:06<00:43,  1.29s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 234\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xbatch, ybatch \u001b[38;5;129;01min\u001b[39;00m tqdm(training, colour\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    232\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 234\u001b[0m     modeloutput \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m     lossval \u001b[38;5;241m=\u001b[39m criterion(modeloutput, ybatch)\n\u001b[0;32m    237\u001b[0m     lossval\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[4], line 192\u001b[0m, in \u001b[0;36mRecurrentNN.forward\u001b[1;34m(object, step)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mobject\u001b[39m, step):\n\u001b[0;32m    191\u001b[0m     step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39mtable(step)\n\u001b[1;32m--> 192\u001b[0m     _,(state,_) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# now we have the Last backward and forward states (hidden)\u001b[39;00m\n\u001b[0;32m    195\u001b[0m     fowardstate  \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1772\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1773\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1780\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1781\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1783\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1784\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1786\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\rnn.py:1124\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m   1121\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1124\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1125\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1128\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1129\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1130\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1131\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1132\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1133\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1134\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   1138\u001b[0m         batch_sizes,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1145\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional,\n\u001b[0;32m   1146\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import all libraries\n",
    "\n",
    "import numpy as np\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from io import BytesIO\n",
    "\n",
    "# from google.colab import files\n",
    "# uploaded = files.upload()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Here we train an RNN (with LSTM) predicting which player from the pool\n",
    "# has participated in the game based on only the played moves.\n",
    "\n",
    "\n",
    "\n",
    "# Setup\n",
    "\n",
    "# import games in csv\n",
    "Csv = \"filtered_games.csv\"\n",
    "\n",
    "# Player names\n",
    "Players = [\n",
    "    \"Carlsen, Magnus\", \"Firouzja, Alireza\", \"Caruana, Fabiano\",\n",
    "    \"Nepomniachtchi, Ian\", \"Cramling Bellon, Anna\", \"Giri, Anish\",\n",
    "    \"Niemann, Hans Moke\", \"Cramling, Pia\", \"Nakamura, Hikaru\",\n",
    "    \"Botez, Alexandra\", \"Botez, Andrea\", \"Belenkaya, Dina\",\n",
    "    \"So, Wesley\",\n",
    "]\n",
    "\n",
    "# We use only 4 players\n",
    "Players = Players[:4]\n",
    "\n",
    "# Initialize batch size, needs to be big here for faster\n",
    "# simulations on the laptop, and smaller when using LUMI\n",
    "Batchsize = 32\n",
    "\n",
    "# Define the lngth of the games (small for laptop and\n",
    "# big when using LUMI)\n",
    "Game_Length = 100\n",
    "\n",
    "# Step size / Learning rate for the Adam optimizer\n",
    "Stepsize = 2e-3\n",
    "\n",
    "# Iterations / Epochs\n",
    "Iterations = 50\n",
    "\n",
    "# LSTM hidden dimension\n",
    "LSTM_Hidden = 128\n",
    "\n",
    "# Embedding dimension\n",
    "Dimension_Embedded = 128\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Data loadeing\n",
    "\n",
    "data = pd.read_csv(Csv) # loading into dataframe\n",
    "\n",
    "\n",
    "# we set names (coloumns) as strings\n",
    "data[\"white_name\"] = data[\"white_name\"].astype(str)\n",
    "data[\"black_name\"] = data[\"black_name\"].astype(str)\n",
    "\n",
    "\n",
    "\n",
    "# Now we only want to do this for top 4 players (with most data)\n",
    "# Since we are running this on a laptop and for the dataset to\n",
    "# be more balanced\n",
    "def player_match(name:str):\n",
    "    # Return player name if in sub-string\n",
    "    lowered = name.lower()\n",
    "    for player in Players:\n",
    "        if player.lower() == lowered:\n",
    "            return player\n",
    "    return None\n",
    "\n",
    "# Now determining player of each game\n",
    "w = data[\"white_name\"].apply(player_match)\n",
    "b = data[\"black_name\"].apply(player_match)\n",
    "data[\"PlayerLabel\"] = w.fillna(b) # if not white go back to black\n",
    "\n",
    "# Remove all other games\n",
    "data = data.dropna(subset=[\"PlayerLabel\"]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# now we map locally\n",
    "encodep = dict(zip(Players, range(len(Players))))\n",
    "decodep = {m: l for l, m in encodep.items()}\n",
    "\n",
    "\n",
    "# we make a temperory split for training tokenization\n",
    "dat_temp = data\n",
    "l = len(dat_temp)\n",
    "\n",
    "traindata, _, _ = random_split(\n",
    "    range(l),\n",
    "    [int(l*0.8), int(l*0.1), l - int(l*0.8) - int(l*0.1)], # test data\n",
    "    generator=torch.Generator().manual_seed(123) # seed\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tokenization (from used steps/moves)\n",
    "\n",
    "# Using cleaner to take unwanted things out\n",
    "cleaner = str.maketrans({\"[\": \"\", \"]\": \"\", \"'\": \"\", \",\": \"\"})\n",
    "all_step = [ # flatten moves from games\n",
    "    k\n",
    "    for s in data.loc[traindata.indices, \"list_of_moves\"]\n",
    "    for k in s.translate(cleaner).split()\n",
    "]\n",
    "# count frequency of moves\n",
    "frequency = Counter(all_step)\n",
    "\n",
    "# keeping it simple (just anything we dont know)\n",
    "Dir = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "# Assign id\n",
    "Dir.update({n: len(Dir) + i for i, n in enumerate(frequency)})\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def step_encode(step): # convert raw mos into tokens\n",
    "    # This pads using zeroes and trunctaes with game-lenth\n",
    "    cleaned = step.translate(str.maketrans({\"[\": \"\", \"]\": \"\", \"'\": \"\", \",\": \"\"}))\n",
    "    tokening = cleaned.split()\n",
    "    # use ids\n",
    "    # use UNK(1) when it is unknown\n",
    "    vector = list(map(lambda i_token: Dir.get(i_token, 1), tokening[: Game_Length]))\n",
    "    pad = np.zeros(Game_Length - len(vector), dtype=int).tolist()\n",
    "    vector = vector + pad\n",
    "    return vector\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now we handle the data in a class\n",
    "\n",
    "class Gamesequence(Dataset): # wrapping dataset\n",
    "    def __init__(object, wind): # store frame\n",
    "        object.win = wind\n",
    "        # convert names inot int labeling for class\n",
    "        object.labels = wind[\"PlayerLabel\"].map(encodep).to_list()\n",
    "        object.moves  = wind[\"list_of_moves\"].to_list() # save for encoding\n",
    "\n",
    "    def __len__(object): # pytorch standard\n",
    "        length = object.win.__len__() # nr of samples\n",
    "        return length\n",
    "\n",
    "    def __getitem__(object, m): # get training from index\n",
    "        # id's of tokens\n",
    "        x = torch.tensor(step_encode(object.moves[m]), dtype=torch.long)\n",
    "        # player\n",
    "        y = torch.tensor(object.labels[m], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now we spilt the data into train, validation and\n",
    "# test data as learnt in the lectures\n",
    "\n",
    "# Use 80, 10, 10 split\n",
    "dat = Gamesequence(data)\n",
    "l = len(dat)\n",
    "traindata, validationdata, testdata = random_split(\n",
    "    dat,\n",
    "    [int(l * 0.8), # train data\n",
    "     int(l * 0.1), # validation data\n",
    "     # to avoid rounding problems we subtract:\n",
    "     l - int(l * 0.8) - int(l * 0.1)], # test data\n",
    "    generator=torch.Generator().manual_seed(123)\n",
    "    # we choose seed 123 this time, works better\n",
    ")\n",
    "\n",
    "# Suffle only train, not the others\n",
    "training = DataLoader(traindata, batch_size = Batchsize, shuffle = True)\n",
    "validating = DataLoader(validationdata, batch_size = Batchsize)\n",
    "testing = DataLoader(testdata, batch_size = Batchsize)\n",
    "\n",
    "\n",
    "# Cross Entropy loss (ideal and simple for classification tasks)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now we build the RNN model with  2-layer bidirectional LSTM\n",
    "\n",
    "class RecurrentNN(nn.Module):\n",
    "    def __init__(object, Dir, Dimension_Embedded, LSTM_Hidden, Dimension_out):\n",
    "        super(RecurrentNN, object).__init__() # initilaze pytorch nn.module\n",
    "\n",
    "        # lookup table for the tokens\n",
    "        object.table = nn.Embedding( # embedding for tokens\n",
    "            num_embeddings=Dir,\n",
    "            embedding_dim=Dimension_Embedded, # size of embeddings\n",
    "            padding_idx=0 # telling torch 0's are padding, not actual moves\n",
    "        )\n",
    "\n",
    "        # Core\n",
    "        object.core = nn.LSTM( # lstm core\n",
    "            input_size=Dimension_Embedded, # use embedding vector\n",
    "            # hidden dimension\n",
    "            hidden_size=LSTM_Hidden,\n",
    "            # 2 layers for a bit better results\n",
    "            num_layers=2,\n",
    "            batch_first=True,\n",
    "            bidirectional=True, # backward and forward\n",
    "            dropout=0.25 # minimizing overfitting (drop 25% units randomly)\n",
    "            # For 2 layers it is ignored but for layers >= 3 (for later) it is good to have\n",
    "        )\n",
    "\n",
    "        # projection block outputting\n",
    "        object.proj = nn.Sequential( # classifier part\n",
    "            nn.Dropout(0.35), # same like before (being less dependent on single neurons)\n",
    "            nn.Linear(2 * LSTM_Hidden, Dimension_out) # since bidirectional\n",
    "        )\n",
    "\n",
    "    def forward(object, step): # input flow\n",
    "        step = object.table(step) # embedding tokens\n",
    "        _,(state,_) = object.core(step) # running sequence\n",
    "\n",
    "        # now we have the Last backward and forward states (hidden)\n",
    "        fowardstate  = state[-2] # for 2 layers\n",
    "        backwardstate = state[-1]\n",
    "\n",
    "        # here we have a single vector concatenation\n",
    "        vector = torch.cat([fowardstate, backwardstate], dim=1)\n",
    "\n",
    "        return object.proj(vector)\n",
    "\n",
    "model = RecurrentNN( # Building model\n",
    "    Dir=len(Dir),\n",
    "    Dimension_Embedded=Dimension_Embedded,\n",
    "    LSTM_Hidden=LSTM_Hidden,\n",
    "    Dimension_out=len(encodep)\n",
    ").to(device)\n",
    "\n",
    "# Use adam optimizer as i almost always do\n",
    "optimization = torch.optim.Adam(\n",
    "    params=list(model.parameters()),\n",
    "    lr=Stepsize\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now we train\n",
    "\n",
    "vbest = 0.0\n",
    "pat = 10\n",
    "count_pat = 0\n",
    "mbest = None\n",
    "\n",
    "for iter in range(Iterations): # run iterations/epoch\n",
    "\n",
    "    model.train() # training mode activation before updating gradients\n",
    "    # Initialize variables\n",
    "    loss_running = 0\n",
    "    hit = 0\n",
    "    seen = 0\n",
    "\n",
    "    for xbatch, ybatch in tqdm(training, colour='green'): # iterating batches\n",
    "        xbatch = xbatch.to(device)\n",
    "        ybatch = ybatch.to(device)\n",
    "\n",
    "        # reset from last batch\n",
    "        optimization.zero_grad()\n",
    "\n",
    "        # forward pass computation\n",
    "        modeloutput = model(xbatch)\n",
    "\n",
    "        # cross entropy loss\n",
    "        lossval = criterion(modeloutput, ybatch)\n",
    "\n",
    "        # back propagate\n",
    "        lossval.backward()\n",
    "\n",
    "        # Update\n",
    "        optimization.step()\n",
    "\n",
    "        # running loss\n",
    "        loss_running += lossval.detach().cpu().item()\n",
    "\n",
    "        # Accuracy (no gradients required)\n",
    "        # Reduces computational cost minimally,\n",
    "        # depending on GPU load\n",
    "        with torch.inference_mode():\n",
    "            # prediction (highest logit)\n",
    "            g = modeloutput.argmax(1)\n",
    "\n",
    "            # hits (correct)\n",
    "            hit += (g == ybatch).sum().item()\n",
    "\n",
    "            # samples processed\n",
    "            seen += ybatch.size(0)\n",
    "\n",
    "    # computing accuracy (avoiding division by 0)\n",
    "    accuracy_training = hit / (1 if seen == 0 else seen)\n",
    "    print(\n",
    "        f\"iteration nr {iter + 1} out of {Iterations}\"\n",
    "        f\" running loss = {loss_running: .4f}\"\n",
    "        f\"\\ntraining accuracy = {accuracy_training: .4f}\"\n",
    "    )\n",
    "\n",
    "    # And validate simultaniously\n",
    "\n",
    "    # same again\n",
    "    model.eval()\n",
    "    hit = 0\n",
    "    seen = 0\n",
    "\n",
    "    with torch.inference_mode(): # without gradient update for evaluation\n",
    "        for x, y in validating:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            modeloutput = model(x)\n",
    "            g = modeloutput.argmax(1)\n",
    "            hit += (g == y).sum().item()\n",
    "            seen += y.size(0)\n",
    "\n",
    "    accuracy_validation = hit / (1 if seen == 0 else seen)\n",
    "\n",
    "    print(f\"validation accuracy = {accuracy_validation: .4f}\")\n",
    "\n",
    "    # early stopping\n",
    "    if accuracy_validation > vbest:\n",
    "        vbest = accuracy_validation\n",
    "        count_pat = 0\n",
    "        # save mbest\n",
    "        mbest = {\n",
    "            k: v.clone().detach().to(device)\n",
    "            for k, v in model.state_dict().items()\n",
    "        }\n",
    "        \n",
    "    else:\n",
    "        count_pat += 1\n",
    "\n",
    "    if count_pat >= pat:\n",
    "        break\n",
    "\n",
    "\n",
    "# use mbest:\n",
    "if mbest is not None:\n",
    "    model.load_state_dict(mbest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Now we test on the test data at the end\n",
    "\n",
    "# same again\n",
    "model.eval()\n",
    "hit = 0\n",
    "seen = 0\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for x, y in testing:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        modeloutput = model(x)\n",
    "        g = modeloutput.argmax(1)\n",
    "        hit += (g == y).sum().item()\n",
    "        seen += y.size(0)\n",
    "\n",
    "accuracy_test = hit / (1 if seen == 0 else seen)\n",
    "print(f\"test accuracy = {accuracy_test: .4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
